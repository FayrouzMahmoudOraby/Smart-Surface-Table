{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24ddd639-afdc-46f5-9b5a-705019894de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mediapipe in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (0.10.18)\n",
      "Requirement already satisfied: pyautogui in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (0.9.54)\n",
      "Requirement already satisfied: pandas in e:\\anaconda\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: pygetwindow in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (0.0.9)\n",
      "Requirement already satisfied: absl-py in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (24.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (24.3.25)\n",
      "Requirement already satisfied: jax in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (0.4.35)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (0.4.35)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (3.9.2)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (1.26.4)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (4.10.0.84)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (4.25.5)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (0.5.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (0.2.0)\n",
      "Requirement already satisfied: pymsgbox in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from pyautogui) (1.0.9)\n",
      "Requirement already satisfied: pytweening>=1.0.4 in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from pyautogui) (1.2.0)\n",
      "Requirement already satisfied: pyscreeze>=0.1.21 in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from pyautogui) (1.0.1)\n",
      "Requirement already satisfied: mouseinfo in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from pyautogui) (0.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\anaconda\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\anaconda\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: pyrect in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from pygetwindow) (0.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.4.0 in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from jax->mediapipe) (0.5.0)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.10 in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from jax->mediapipe) (1.14.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (3.2.0)\n",
      "Requirement already satisfied: pyperclip in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from mouseinfo->pyautogui) (1.9.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\fayroz\\appdata\\roaming\\python\\python312\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mediapipe pyautogui pandas pygetwindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aefc08d8-139d-4aa0-9cee-b345f73a1ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is listening... Waiting for a client to connect.\n",
      "Connected to ('127.0.0.1', 58976)\n",
      "Swipe detected, Alt + Tab triggered!\n",
      "Swipe detected, Alt + Tab triggered!\n",
      "Swipe detected, Alt + Tab triggered!\n",
      "Transition from open hand to closed fist detected! Closing active application...\n",
      "Swipe detected, Alt + Tab triggered!\n",
      "Swipe detected, Alt + Tab triggered!\n",
      "Swipe detected, Alt + Tab triggered!\n",
      "Transition from open hand to closed fist detected! Closing active application...\n",
      "Transition from open hand to closed fist detected! Closing active application...\n",
      "Transition from open hand to closed fist detected! Closing active application...\n",
      "Swipe detected, Alt + Tab triggered!\n",
      "Swipe detected, Alt + Tab triggered!\n",
      "Swipe detected, Alt + Tab triggered!\n",
      "Swipe detected, Alt + Tab triggered!\n",
      "Swipe detected, Alt + Tab triggered!\n",
      "Volume Up\n",
      "Swipe detected, Alt + Tab triggered!\n",
      "Swipe detected, Alt + Tab triggered!\n",
      "Swipe detected, Alt + Tab triggered!\n",
      "Swipe detected, Alt + Tab triggered!\n",
      "Hands are far apart - Stopping code\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import pyautogui\n",
    "import time\n",
    "import pygetwindow as gw\n",
    "import socket\n",
    "import numpy as np\n",
    "\n",
    "soc = socket.socket()\n",
    "hostname = \"localhost\"\n",
    "port = 65436\n",
    "soc.bind((hostname, port))\n",
    "soc.listen(1)\n",
    "print(\"Server is listening... Waiting for a client to connect.\")\n",
    "conn, addr = soc.accept()\n",
    "print(f\"Connected to {addr}\")\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "debounce_time = 0.5  # Time in seconds\n",
    "last_trigger_time = time.time()\n",
    "\n",
    "\n",
    "def send_command_to_client(command):\n",
    "    global conn\n",
    "    if conn:\n",
    "        try:\n",
    "            conn.sendall(command.encode('utf-8'))\n",
    "        except (ConnectionAbortedError, ConnectionResetError, BrokenPipeError) as e:\n",
    "            conn = None\n",
    "\n",
    "def calculate_distance(x1, y1, x2, y2):\n",
    "    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "\n",
    "def distance_close(results, frame, distance_threshold):\n",
    "    if len(results.multi_hand_landmarks) == 2:\n",
    "        hand_1_wrist = results.multi_hand_landmarks[0].landmark[mp_hands.HandLandmark.WRIST]\n",
    "        hand_2_wrist = results.multi_hand_landmarks[1].landmark[mp_hands.HandLandmark.WRIST]\n",
    "\n",
    "        wrist_1_x = int(hand_1_wrist.x * frame.shape[1])\n",
    "        wrist_1_y = int(hand_1_wrist.y * frame.shape[0])\n",
    "        wrist_2_x = int(hand_2_wrist.x * frame.shape[1])\n",
    "        wrist_2_y = int(hand_2_wrist.y * frame.shape[0])\n",
    "\n",
    "        distance = np.sqrt((wrist_2_x - wrist_1_x) ** 2 + (wrist_2_y - wrist_1_y) ** 2)\n",
    "        return distance\n",
    "    return None\n",
    "\n",
    "def maximize_window():\n",
    "    global last_trigger_time\n",
    "    current_time = time.time()\n",
    "    if current_time - last_trigger_time > debounce_time:  # Debounce check\n",
    "        active_window = gw.getActiveWindow()\n",
    "        if active_window:\n",
    "            active_window.activate()\n",
    "            time.sleep(0.5)\n",
    "            active_window.maximize()\n",
    "            send_command_to_client(\"maximize\\n\")\n",
    "            last_trigger_time = current_time  # Update last trigger time\n",
    "\n",
    "def restore_window():\n",
    "    global last_trigger_time\n",
    "    current_time = time.time()\n",
    "    if current_time - last_trigger_time > debounce_time:  # Debounce check\n",
    "        active_window = gw.getActiveWindow()\n",
    "        if active_window:\n",
    "            active_window.restore()\n",
    "            screen_width, screen_height = pyautogui.size()\n",
    "            half_width = screen_width // 2\n",
    "            active_window.resizeTo(half_width, screen_height)\n",
    "            active_window.moveTo(0, 0)\n",
    "            send_command_to_client(\"restore\\n\")\n",
    "            last_trigger_time = current_time  # Update last trigger time\n",
    "\n",
    "def detect_gesture(hand_landmarks, previous_x, frame, swipe_threshold=60):\n",
    "    global last_trigger_time\n",
    "    x = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].x * frame.shape[1]\n",
    "\n",
    "    if previous_x is not None:\n",
    "        if x - previous_x > swipe_threshold:\n",
    "            current_time = time.time()\n",
    "            if current_time - last_trigger_time > debounce_time:  # Debounce check\n",
    "                pyautogui.keyDown('alt')\n",
    "                pyautogui.press('tab')\n",
    "                pyautogui.keyUp('alt')\n",
    "\n",
    "                msg = b\"Swipe detected, Alt + Tab triggered!\\n\"\n",
    "                try:\n",
    "                    conn.send(msg)\n",
    "                    print(\"Swipe detected, Alt + Tab triggered!\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error sending message: {e}\")\n",
    "\n",
    "                last_trigger_time = current_time  # Update last trigger time\n",
    "\n",
    "    return x \n",
    "\n",
    "def volume_up():\n",
    "    global last_trigger_time\n",
    "    current_time = time.time()\n",
    "    if current_time - last_trigger_time > debounce_time:  # Debounce check\n",
    "        pyautogui.press('volumeup')\n",
    "        print(\"Volume Up\")\n",
    "        send_command_to_client(\"volume_up\\n\")\n",
    "        last_trigger_time = current_time  # Update last trigger time\n",
    "\n",
    "def volume_down():\n",
    "    global last_trigger_time\n",
    "    current_time = time.time()\n",
    "    if current_time - last_trigger_time > debounce_time:  # Debounce check\n",
    "        pyautogui.press('volumedown')\n",
    "        print(\"Volume Down\")\n",
    "        send_command_to_client(\"volume_down\\n\")\n",
    "        last_trigger_time = current_time  # Update last trigger time\n",
    "\n",
    "def is_open_hand(landmarks):\n",
    "    index_tip = landmarks[8]\n",
    "    middle_tip = landmarks[12]\n",
    "    ring_tip = landmarks[16]\n",
    "    pinky_tip = landmarks[20]\n",
    "    return (\n",
    "        index_tip.y < landmarks[6].y and\n",
    "        middle_tip.y < landmarks[10].y and\n",
    "        ring_tip.y < landmarks[14].y and\n",
    "        pinky_tip.y < landmarks[18].y\n",
    "    )\n",
    "\n",
    "def is_closed_fist(landmarks):\n",
    "    thumb_tip = landmarks[4]\n",
    "    index_tip = landmarks[8]\n",
    "    middle_tip = landmarks[12]\n",
    "    ring_tip = landmarks[16]\n",
    "    pinky_tip = landmarks[20]\n",
    "    return (\n",
    "        thumb_tip.x < landmarks[3].x and\n",
    "        index_tip.y > landmarks[6].y and\n",
    "        middle_tip.y > landmarks[10].y and\n",
    "        ring_tip.y > landmarks[14].y and\n",
    "        pinky_tip.y > landmarks[18].y\n",
    "    )\n",
    "\n",
    "def close_active_window():\n",
    "    global last_trigger_time\n",
    "    current_time = time.time()\n",
    "    if current_time - last_trigger_time > debounce_time:  # Debounce check\n",
    "        active_window = gw.getActiveWindow()\n",
    "        if active_window:\n",
    "            window_title = active_window.title\n",
    "            print(f\"Attempting to close: {window_title}\")\n",
    "            pyautogui.hotkey('ctrl', 'w')\n",
    "            message = f\"Closed fist detected! Application closed: {window_title}\"\n",
    "            send_command_to_client(message)\n",
    "            print(f\"Sent message: {message}\")\n",
    "        else:\n",
    "            print(\"No active window detected.\")\n",
    "            send_command_to_client(\"No active window detected.\")\n",
    "        last_trigger_time = current_time  # Update last trigger time\n",
    "\n",
    "movement_threshold = 60  # Adjust this based on screen size and sensitivity\n",
    "previous_y = None\n",
    "was_open_hand = False\n",
    "with mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7) as hands:\n",
    "    previous_x = None\n",
    "    while cap.isOpened():\n",
    "        _, frame = cap.read()\n",
    "        try:\n",
    "            f_frame = cv2.flip(frame, 1)\n",
    "            frame_rgb = cv2.cvtColor(f_frame, cv2.COLOR_BGR2RGB)\n",
    "            results = hands.process(frame_rgb)\n",
    "\n",
    "            annotated_image = f_frame.copy()\n",
    "\n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "                    index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                    thumb_x = thumb_tip.x\n",
    "                    thumb_y = thumb_tip.y\n",
    "                    index_x = index_tip.x\n",
    "                    index_y = index_tip.y\n",
    "                    mp_drawing.draw_landmarks(annotated_image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                    previous_x = detect_gesture(hand_landmarks, previous_x, frame)\n",
    "\n",
    "                    distance = calculate_distance(thumb_x, thumb_y, index_x, index_y)\n",
    "\n",
    "                    wrist_y = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].y * frame.shape[0]\n",
    "\n",
    "                \n",
    "                    if previous_y is not None:\n",
    "                        movement = wrist_y - previous_y\n",
    "    \n",
    "                        # Volume up if hand moves upward, down if downward\n",
    "                        if movement < -movement_threshold:\n",
    "                            volume_up()\n",
    "                        elif movement > movement_threshold:\n",
    "                            volume_down()\n",
    "    \n",
    "                    # Update previous_y to current y-coordinate of the wrist\n",
    "                    previous_y = wrist_y\n",
    "\n",
    "                    if distance > 0.2:\n",
    "                        maximize_window()\n",
    "                    elif distance < 0.1:\n",
    "                        restore_window()\n",
    "\n",
    "                distance = distance_close(results, frame, 450)\n",
    "                if distance is not None:\n",
    "                    cv2.putText(annotated_image, f\"Distance: {int(distance)}\", (50, 50),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "                    if distance > 450:\n",
    "                        print(\"Hands are far apart - Stopping code\")\n",
    "                        send_command_to_client(\"Hands are far apart - Stopping code\\n\")\n",
    "                        send_command_to_client(\"quit\\n\")\n",
    "                        break\n",
    "\n",
    "                landmarks = hand_landmarks.landmark\n",
    "\n",
    "                # Check gestures\n",
    "                if is_open_hand(landmarks):\n",
    "                    was_open_hand = True\n",
    "                elif was_open_hand and is_closed_fist(landmarks):\n",
    "                    print(\"Transition from open hand to closed fist detected! Closing active application...\")\n",
    "                    close_active_window()\n",
    "                    send_command_to_client(\"Closed fist detected! Application closed.\")\n",
    "                    time.sleep(1)\n",
    "                    was_open_hand = False\n",
    "\n",
    "\n",
    "            \n",
    "            else:\n",
    "                previous_y = None\n",
    "\n",
    "            cv2.imshow('MediaPipe Hands', annotated_image)\n",
    "\n",
    "        except Exception as e: \n",
    "            print(f\"Error: {e}\")\n",
    "            break\n",
    "\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "conn.close()\n",
    "soc.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60465d67-512f-4848-8d54-d5ce65ddcc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# code work avec 1 hand\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.5)\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "image_path = r\"C:\\Users\\Fayroz\\Pictures\\Saved Pictures\\marvel.jpg\"\n",
    "image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "if image is None:\n",
    "    print(f\"Failed to load image from {image_path}. Check if the file exists and the path is correct.\")\n",
    "else:\n",
    "    print(\"Image loaded successfully.\")\n",
    "\n",
    "image_height, image_width = 150, 200\n",
    "image = cv2.resize(image, (image_width, image_height))\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "x, y = 100, 100\n",
    "previous_x, previous_y = None, None\n",
    "freeze_movement = False  \n",
    "\n",
    "def is_fist(hand_landmarks):\n",
    "    \"\"\"\n",
    "    Detects if the hand is in a fist position.\n",
    "    \"\"\"\n",
    "    finger_tips = [\n",
    "        mp_hands.HandLandmark.INDEX_FINGER_TIP,\n",
    "        mp_hands.HandLandmark.MIDDLE_FINGER_TIP,\n",
    "        mp_hands.HandLandmark.RING_FINGER_TIP,\n",
    "        mp_hands.HandLandmark.PINKY_TIP,\n",
    "    ]\n",
    "    finger_bottoms = [\n",
    "        mp_hands.HandLandmark.INDEX_FINGER_PIP,\n",
    "        mp_hands.HandLandmark.MIDDLE_FINGER_PIP,\n",
    "        mp_hands.HandLandmark.RING_FINGER_PIP,\n",
    "        mp_hands.HandLandmark.PINKY_PIP,\n",
    "    ]\n",
    "\n",
    "    # Check if each finger tip is below or close to its bottom joint\n",
    "    for tip, bottom in zip(finger_tips, finger_bottoms):\n",
    "        if hand_landmarks.landmark[tip].y < hand_landmarks.landmark[bottom].y:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    # Handle only one hand\n",
    "    if results.multi_hand_landmarks:\n",
    "        hand_landmarks = results.multi_hand_landmarks[0]  \n",
    "\n",
    "        if is_fist(hand_landmarks):\n",
    "            freeze_movement = True  # Freeze the movement\n",
    "        else:\n",
    "            freeze_movement = False  # Allow the movement to continue\n",
    "\n",
    "        if not freeze_movement:\n",
    "            index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "            h, w, _ = frame.shape\n",
    "            finger_x = int(index_tip.x * w)\n",
    "            finger_y = int(index_tip.y * h)\n",
    "\n",
    "            if previous_x is not None and previous_y is not None:\n",
    "                dx = finger_x - previous_x\n",
    "                dy = finger_y - previous_y\n",
    "\n",
    "                x += dx\n",
    "                y += dy\n",
    "\n",
    "            previous_x, previous_y = finger_x, finger_y\n",
    "\n",
    "        mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    else:\n",
    "        previous_x, previous_y = None, None\n",
    "\n",
    "    x = max(0, min(x, frame.shape[1] - image_width))\n",
    "    y = max(0, min(y, frame.shape[0] - image_height))\n",
    "\n",
    "    y1, y2 = y, y + image_height\n",
    "    x1, x2 = x, x + image_width\n",
    "    frame[y1:y2, x1:x2] = image\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow(\"Move Picture\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187a6fe4-f98c-45a7-8087-eea16886c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.5)\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "previous_x, previous_y = None, None\n",
    "freeze_movement = False  \n",
    "\n",
    "def is_fist(hand_landmarks):\n",
    "    \"\"\"\n",
    "    Detects if the hand is in a fist position.\n",
    "    \"\"\"\n",
    "    finger_tips = [\n",
    "        mp_hands.HandLandmark.INDEX_FINGER_TIP,\n",
    "        mp_hands.HandLandmark.MIDDLE_FINGER_TIP,\n",
    "        mp_hands.HandLandmark.RING_FINGER_TIP,\n",
    "        mp_hands.HandLandmark.PINKY_TIP,\n",
    "    ]\n",
    "    finger_bottoms = [\n",
    "        mp_hands.HandLandmark.INDEX_FINGER_PIP,\n",
    "        mp_hands.HandLandmark.MIDDLE_FINGER_PIP,\n",
    "        mp_hands.HandLandmark.RING_FINGER_PIP,\n",
    "        mp_hands.HandLandmark.PINKY_PIP,\n",
    "    ]\n",
    "\n",
    "    for tip, bottom in zip(finger_tips, finger_bottoms):\n",
    "        if hand_landmarks.landmark[tip].y < hand_landmarks.landmark[bottom].y:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def is_finger_extended(hand_landmarks, finger_tip, finger_bottom):\n",
    "    \"\"\"\n",
    "    Check if a finger is extended (tip is above bottom joint).\n",
    "    \"\"\"\n",
    "    if hand_landmarks.landmark[finger_tip].y < hand_landmarks.landmark[finger_bottom].y:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        hand_landmarks = results.multi_hand_landmarks[0]  # First hand is used for movement\n",
    "\n",
    "        if is_fist(hand_landmarks):\n",
    "            freeze_movement = True  # Freeze the movement\n",
    "        else:\n",
    "            freeze_movement = False  \n",
    "\n",
    "        index_extended = is_finger_extended(hand_landmarks, mp_hands.HandLandmark.INDEX_FINGER_TIP, mp_hands.HandLandmark.INDEX_FINGER_PIP)\n",
    "        middle_extended = is_finger_extended(hand_landmarks, mp_hands.HandLandmark.MIDDLE_FINGER_TIP, mp_hands.HandLandmark.MIDDLE_FINGER_PIP)\n",
    "\n",
    "        if not freeze_movement:\n",
    "            index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "            h, w, _ = frame.shape\n",
    "            finger_x = int(index_tip.x * w)\n",
    "            finger_y = int(index_tip.y * h)\n",
    "\n",
    "            if previous_x is not None and previous_y is not None:\n",
    "                dx = finger_x - previous_x\n",
    "                dy = finger_y - previous_y\n",
    "\n",
    "                screen_x = int(finger_x * screen_width / w)\n",
    "                screen_y = int(finger_y * screen_height / h)\n",
    "\n",
    "                pyautogui.moveTo(screen_x, screen_y)\n",
    "\n",
    "                if index_extended and middle_extended:\n",
    "                    pyautogui.click()\n",
    "\n",
    "            previous_x, previous_y = finger_x, finger_y\n",
    "\n",
    "        mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    else:\n",
    "        previous_x, previous_y = None, None\n",
    "\n",
    "    cv2.imshow(\"Hand Tracking\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
